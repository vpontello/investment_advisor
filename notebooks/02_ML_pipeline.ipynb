{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline\n",
    "\n",
    "This notebook contains the ML Pipeline for the model training\n",
    "\n",
    "## Libraries and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts.utils import initialize_bucket, plot_importance\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import KFold, cross_val_score,cross_validate\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer, explained_variance_score,mean_absolute_percentage_error\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import shap\n",
    "\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 400)\n",
    "\n",
    "credentials_path = '../datascience-capstone-project-05b1642f45c3.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client, bucket = initialize_bucket(credentials_path,'storage-barsianize')\n",
    "\n",
    "path = \"gs://storage-barsianize/05_datasets/df_base_dataset.parquet\"\n",
    "df =  pd.read_parquet(path)\n",
    "\n",
    "path = \"gs://storage-barsianize/05_datasets/df_to_pred.parquet\"\n",
    "df_to_pred =  pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods and functions\n",
    "\n",
    "### Build and train pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipelines(regressors, transformers):\n",
    "    pipelines = {}\n",
    "\n",
    "    for transformer in transformers:\n",
    "        for algorithm,regressor in regressors.items():\n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessing', transformer),\n",
    "                ('reg',regressor)\n",
    "            ])\n",
    "            pipelines[algorithm + '_' + str(transformer)] = pipeline\n",
    "\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models(regressors,parameters_dict, transformers):\n",
    "    pipelines = build_pipelines(regressors, transformers)\n",
    "\n",
    "    cvs = {}\n",
    "    \n",
    "    for transformer in transformers:\n",
    "        for algorithm,parameters in parameters_dict.items():\n",
    "            # create grid search object\n",
    "            cv = GridSearchCV(pipelines[algorithm + '_' + str(transformer)], cv=5, param_grid=parameters, scoring='r2')\n",
    "            cvs[algorithm + '_' + str(transformer)] = cv\n",
    "\n",
    "    print(cvs)\n",
    "    \n",
    "    return cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_and_store_results(X, y, y_test, y_pred, model, algorithm, sufix):\n",
    "\n",
    "    # define the cross-validation method (e.g. KFold with 5 folds)\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    # define the evaluation metrics (r2 score and mean squared error)\n",
    "    scoring = {'r2': make_scorer(r2_score), \n",
    "               'mse': make_scorer(mean_squared_error),\n",
    "               'xve': make_scorer(explained_variance_score),\n",
    "               'MAPE': make_scorer(mean_absolute_percentage_error)}\n",
    "    # perform cross-validation and get the scores\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "    print(scores)\n",
    "    scores['fit_time']  = scores['fit_time'].tolist() \n",
    "    scores['score_time']= scores['score_time'].tolist() \n",
    "    scores['test_r2']   = scores['test_r2'].tolist() \n",
    "    scores['test_mse']  = scores['test_mse'].tolist()\n",
    "    scores['test_xve']  = scores['test_xve'].tolist()\n",
    "    scores['test_MAPE'] = scores['test_MAPE'].tolist()\n",
    "\n",
    "    print('CV R2 score:', np.mean(scores['test_r2']))\n",
    "    print('CV MSE:', np.mean(scores['test_mse']))\n",
    "\n",
    "    performance = {}\n",
    "\n",
    "    test_score_r2 = r2_score(y_test, y_pred)\n",
    "    test_score_mse = mean_squared_error(y_test, y_pred)\n",
    "    test_score_xvs = explained_variance_score(y_test, y_pred)\n",
    "    test_score_mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    print('test r2:', test_score_r2)\n",
    "    print('test mse:', test_score_mse)\n",
    "    print('test explained_variance_score:', test_score_xvs)\n",
    "    print('test MAPE:', test_score_mape)\n",
    "\n",
    "    performance['cv_scores'] = scores\n",
    "    performance['test_scores'] = {}\n",
    "    performance['test_scores']['r2'] = test_score_r2\n",
    "    performance['test_scores']['mse'] = test_score_mse\n",
    "    performance['test_scores']['explained_variance_score'] = test_score_xvs\n",
    "    performance['test_scores']['MAPE'] = test_score_mape\n",
    "    \n",
    "    print('___________________________________')\n",
    "        \n",
    "    print(\"\\nBest Parameters:\", model.best_params_)\n",
    "    print('##################################')\n",
    "\n",
    "    performance = {\n",
    "        'algorithm':algorithm,\n",
    "        'best_params':model.best_params_,\n",
    "        'performance':performance,\n",
    "        'features':X.columns.to_list()\n",
    "    }\n",
    "\n",
    "    patch = '../data/03_models/out/'\n",
    "    filename = patch + f'{str(date.today())}_{algorithm}'\n",
    "\n",
    "    # return performance\n",
    "    if sufix != '':\n",
    "        sufix_ = '_' + sufix\n",
    "    else:\n",
    "        sufix_ = sufix\n",
    "\n",
    "    json.dump(performance, open(filename+f'_results{sufix_}.json', 'w'))   \n",
    "    pickle.dump(model.best_estimator_, open(filename+f'{sufix_}.pkl', 'wb'))\n",
    "\n",
    "    return test_score_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(df, params_path, label, regressors, transformers, cols_to_drop=None, cols_to_train=None, sufix=\"\"):\n",
    "\n",
    "    # separating the train and target features\n",
    "    if cols_to_train == None:\n",
    "        X = df.drop(cols_to_drop, axis=1)\n",
    "    elif cols_to_train != None:\n",
    "        print('here we go again')\n",
    "        X = df[cols_to_train]\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "    y = df[label]\n",
    "\n",
    "    with open(params_path) as json_file:\n",
    "        parameters = json.load(json_file)\n",
    "        for key_1, value_1 in parameters.items():\n",
    "            for key_2, value_2 in value_1.items():\n",
    "                parameters[key_1][key_2] = ast.literal_eval(value_2)\n",
    "\n",
    "    models = build_models(regressors,parameters,transformers)\n",
    "\n",
    "    for algorithm, model in models.items():\n",
    "        # X, y = load_data()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=32)\n",
    "\n",
    "        print(algorithm)        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        r2 = display_and_store_results(X, y, y_test, y_pred, model, algorithm, sufix)\n",
    "        print(algorithm, r2)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models and assess results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, model_name):\n",
    "    \n",
    "    with open(path + model_name, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    loaded_model = None\n",
    "    for step_name, step_model in model.named_steps.items():\n",
    "        if isinstance(step_model, LGBMRegressor):\n",
    "            loaded_model = step_model\n",
    "            break\n",
    "        elif isinstance(step_model, XGBRegressor):\n",
    "            loaded_model = step_model\n",
    "            break\n",
    "        elif step_name == 'preprocessing':\n",
    "            transformer = step_model\n",
    "\n",
    "    return loaded_model, transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(path, model_name, results_file, X_to_pred):\n",
    "    # model_name = '2023-08-04_LGBMRegressor_Normalizer()_feat_selection.pkl'\n",
    "    with open(path + model_name, 'rb') as file:\n",
    "        pipeline = pickle.load(file)\n",
    "\n",
    "    with open(path + results_file, 'rb') as json_file:\n",
    "        results = json.load(json_file)\n",
    "\n",
    "    model, transformer = load_model(path, model_name)\n",
    "\n",
    "    features = results['features']\n",
    "\n",
    "    return pipeline.predict(X_to_pred[features]), pipeline, model, transformer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(model, model_class, features):\n",
    "    if 'LGB' in model_class:\n",
    "        feature_importances = model.booster_.feature_importance(importance_type='gain')\n",
    "    elif 'XGB' in model_class:\n",
    "        feature_importances = model.get_booster().get_score(importance_type='gain').values()\n",
    "        \n",
    "    # Create a dictionary to associate feature names with their importance scores\n",
    "    feature_importance_dict = dict(zip(features, feature_importances))\n",
    "    df_feature_importance = pd.DataFrame(feature_importance_dict, \n",
    "                                      index=['Total gain']).T.sort_values(by='Total gain', ascending=False)\n",
    "    return df_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shap_values(model, transformer, X_train, X_test, path, filename, plot=False):\n",
    "    # If the LightGBM model is found, convert it to a LightGBM Booster object and prepare the explainer\n",
    "    if model is not None:\n",
    "        # Assuming you have your test data in 'X_test' (replace 'X_test' with your actual test data)\n",
    "        explainer = shap.Explainer(model, transformer.transform(X_train))\n",
    "\n",
    "        # Calculate SHAP values for the test data\n",
    "        shap_values = explainer(transformer.transform(X_test), check_additivity=False)\n",
    "\n",
    "        # Save SHAP values to a file using pickle\n",
    "        with open(path + filename, 'wb') as file:\n",
    "            pickle.dump(shap_values, file)\n",
    "\n",
    "        # plot shap summary if desired\n",
    "        if plot:\n",
    "            shap.summary_plot(shap_values, X_test)\n",
    "        \n",
    "        # Return SHAP values\n",
    "        return shap_values\n",
    "    \n",
    "    else:\n",
    "        print(\"LightGBM model not found in the pipeline.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models\n",
    "\n",
    "### Training baseline Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_path = '../data/03_models/in/params.json'\n",
    "\n",
    "cols_to_drop = ['year_month','Papel','Empresa','dy_label']\n",
    "label = ['dy_label']\n",
    "\n",
    "regressors = {\n",
    "            'LGBMRegressor':LGBMRegressor(),\n",
    "            'XGBRegressor':XGBRegressor(),\n",
    "        }\n",
    "\n",
    "transformers = [Normalizer()]\n",
    "\n",
    "models = train_models(df, params_path, label, regressors, transformers, cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Results from baseline Model\n",
    "\n",
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_date = date.today()\n",
    "# ref_date = '2023-08-08'\n",
    "\n",
    "path = '../data/03_models/out/'\n",
    "model_name = f'{ref_date}_LGBMRegressor_Normalizer().pkl'\n",
    "results_file = f'{ref_date}_LGBMRegressor_Normalizer()_results.json'\n",
    "\n",
    "df_to_pred['dy_pred_LN'], lgb_pipeline, lgb_model, lgb_model_transformer, lgb_model_features = make_predictions(path, model_name, results_file, X_to_pred)\n",
    "\n",
    "\n",
    "\n",
    "model_name = f'{ref_date}_XGBRegressor_Normalizer().pkl'\n",
    "model_name = f'{ref_date}_XGBRegressor_Normalizer().pkl'\n",
    "results_file = f'{ref_date}_XGBRegressor_Normalizer()_results.json'\n",
    "\n",
    "df_to_pred['dy_pred_XN'], xgb_pipeline, xgb_model, xgb_model_transformer, xgb_model_features = make_predictions(path, model_name, results_file, X_to_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get feature importances based on Total Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_feature_importance = get_feature_importances(xgb_model, 'XGB', X.columns.to_list())\n",
    "plot_importance(xgb_feature_importance, 'Total gain', 'XGBoost Model [Total gain]')\n",
    "\n",
    "lgb_feature_importance = get_feature_importances(lgb_model, 'LGB', X.columns.to_list())\n",
    "plot_importance(lgb_feature_importance, 'Total gain', 'LightGBM Model [Total gain]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get feature importances based on SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_date = '2023-08-08'\n",
    "ref_date = date.today()\n",
    "\n",
    "X = df[xgb_model_features]\n",
    "y = df['dy_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=32)\n",
    "\n",
    "path = '../data/03_models/out/'\n",
    "file_name_shap = f'{ref_date}_XGBRegressor_Normalizer()_SHAP.pkl'\n",
    "\n",
    "xgb_shap = calculate_shap_values(xgb_model, xgb_model_transformer, X_train, X_test, path, file_name_shap, plot=True)\n",
    "\n",
    "# Save SHAP values to a file using pickle\n",
    "with open(path + file_name_shap, 'wb') as file:\n",
    "    pickle.dump(xgb_shap, file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = df[lgb_model_features]\n",
    "y = df['dy_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=32)\n",
    "\n",
    "file_name_shap = f'{ref_date}_LGBMRegressor_Normalizer()_SHAP.pkl'\n",
    "\n",
    "lgb_shap = calculate_shap_values(lgb_model, lgb_model_transformer, X_train, X_test, path, file_name_shap, plot=True)\n",
    "\n",
    "\n",
    "# Save SHAP values to a file using pickle\n",
    "with open(path + file_name_shap, 'wb') as file:\n",
    "    pickle.dump(lgb_shap, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(xgb_model_features,np.abs(np.sum(xgb_shap.values, axis=0))))\n",
    "df_xgb_shap = pd.DataFrame(d, index=['shap_values']).T.sort_values(by='shap_values', ascending=False)\n",
    "\n",
    "d = dict(zip(lgb_model_features,np.abs(np.sum(lgb_shap.values, axis=0))))\n",
    "df_lgb_shap = pd.DataFrame(d, index=['shap_values']).T.sort_values(by='shap_values', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train feature selection model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load baseline models' feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_date = '2023-08-08'\n",
    "ref_date = date.today()\n",
    "\n",
    "path = '../data/03_models/out/'\n",
    "\n",
    "\n",
    "file_name_shap = f'{ref_date}_XGBRegressor_Normalizer()_SHAP.pkl'\n",
    "\n",
    "with open(path + file_name_shap, 'rb') as file:\n",
    "        xgb_shap = pickle.load(file)\n",
    "\n",
    "\n",
    "file_name_shap = f'{ref_date}_LGBMRegressor_Normalizer()_SHAP.pkl'\n",
    "\n",
    "with open(path + file_name_shap, 'rb') as file:\n",
    "        lgb_shap = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the most important features from the XGBoost and LightGBM models, through the intersection of the first 60 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 60\n",
    "\n",
    "intersection_lgb_xgb = np.isin(df_lgb_shap.iloc[:n].index,df_xgb_shap.iloc[:n].index)\n",
    "intersection_xgb_lgb = np.isin(df_xgb_shap.iloc[:n].index,df_lgb_shap.iloc[:n].index)\n",
    "cols_to_train = df_lgb_shap.iloc[:n].loc[intersection_lgb_xgb].index.to_list()\n",
    "\n",
    "print('lgb in xgb ',np.mean(intersection_lgb_xgb))\n",
    "print('xgb in lgb ',np.mean(intersection_xgb_lgb))\n",
    "print('double check, cross intersection value', \n",
    "      np.isin(df_lgb_shap.iloc[:n].loc[intersection_lgb_xgb].index,df_xgb_shap.iloc[:n].loc[intersection_xgb_lgb].index).mean())\n",
    "print('\\n\\ncols to train:\\n')\n",
    "for col in  cols_to_train:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train new feature selection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_path = '../data/03_models/in/params_optimized.json'\n",
    "\n",
    "cols_to_drop = ['year_month','Papel','Empresa','dy_label']\n",
    "label = ['dy_label']\n",
    "\n",
    "regressors = {\n",
    "            'LGBMRegressor':LGBMRegressor(),\n",
    "            'XGBRegressor':XGBRegressor(),\n",
    "        }\n",
    "\n",
    "transformers = [Normalizer(),StandardScaler()]\n",
    "\n",
    "models = train_models(df, params_path, label, regressors, transformers, \n",
    "                        cols_to_train=cols_to_train, \n",
    "                        sufix='feat_selection')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
